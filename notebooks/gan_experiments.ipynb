{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMxoAecfI5u6to8qVMpp8yT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **GAN Experiments**"],"metadata":{"id":"36YoBnfxRqyh"}},{"cell_type":"code","source":["!pip install mido"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHZvAkqTYV-4","executionInfo":{"status":"ok","timestamp":1739534550595,"user_tz":0,"elapsed":3400,"user":{"displayName":"Georgi Goranov","userId":"05647327236610301206"}},"outputId":"9e5bad1e-ccca-4a16-ac39-13472321a295"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mido in /usr/local/lib/python3.11/dist-packages (1.3.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido) (24.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28UXGDh9jlwJ","executionInfo":{"status":"ok","timestamp":1739534557545,"user_tz":0,"elapsed":6967,"user":{"displayName":"Georgi Goranov","userId":"05647327236610301206"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"83f511bb-6ac8-4c8a-b396-f8ee494f0ef6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import mido\n","import os\n","\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","if device.type == \"cuda\":\n","    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n","    print(\"Memory Allocated:\", round(torch.cuda.memory_allocated(0)/1024**3, 2), \"GB\")\n","    print(\"Memory Cached:\", round(torch.cuda.memory_reserved(0)/1024**3, 2), \"GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvcXT79TDoza","executionInfo":{"status":"ok","timestamp":1739534557545,"user_tz":0,"elapsed":17,"user":{"displayName":"Georgi Goranov","userId":"05647327236610301206"}},"outputId":"3195bfcc-69f6-4f3d-9fd7-bc99bedf9f2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","GPU Name: Tesla T4\n","Memory Allocated: 0.0 GB\n","Memory Cached: 0.0 GB\n"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","torch.cuda.ipc_collect()\n","torch.autograd.set_detect_anomaly(True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZmoF_olDpS7","executionInfo":{"status":"ok","timestamp":1739534557545,"user_tz":0,"elapsed":17,"user":{"displayName":"Georgi Goranov","userId":"05647327236610301206"}},"outputId":"37418259-79a7-4029-db61-202a4bfb5ad3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7db37f4b2c90>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["metadata = pd.read_csv(\"/content/drive/MyDrive/Piano generation/Project/MAESTRO dataset/maestro-v3.0.0.csv\")"],"metadata":{"id":"6_yu8TTK0B6e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For the GAN architecture, we are going to use a different method of tokenizing the music, inspired by [Olof Morgen](https://arxiv.org/abs/1611.09904). In his work, he modeled each tone as a quadruplet of *tone length, frequency, intensity* and *time spent since the previous tone*. This results in a matrix of shape `(n, 4)`. In this function, if max_values is provided, we also perform normalization to the *tone_length* and *time_since_prev* values. If it's None, we only normalize the frequency and intensity columns."],"metadata":{"id":"mfyaqZ0YRuEb"}},{"cell_type":"code","source":["def preprocess_midi(file_path, max_values=None):\n","    midi = mido.MidiFile(file_path)\n","\n","    time = 0\n","    features = []\n","    note_on_times_intensities = {}\n","    prev_note_on_time = None\n","    time_since_prev = 0\n","\n","    for track in midi.tracks:\n","        for msg in track:\n","            if not msg.is_meta:\n","                time += msg.time\n","\n","                if msg.type == \"note_on\" and msg.dict()[\"velocity\"] > 0:\n","                    time_since_prev = (time - prev_note_on_time) if prev_note_on_time is not None else 0\n","                    note_on_times_intensities[msg.dict()[\"note\"]] = (time, msg.dict()[\"velocity\"])\n","                    prev_note_on_time = time\n","\n","                elif (msg.type == \"note_off\" or (msg.type == \"note_on\" and msg.dict()[\"velocity\"] == 0)) and msg.dict()[\"note\"] in note_on_times_intensities:\n","                    tone_length = time - note_on_times_intensities[msg.dict()[\"note\"]][0]\n","                    frequency = msg.dict()[\"note\"]\n","                    intensity = note_on_times_intensities[msg.dict()[\"note\"]][1]\n","\n","                    features.append([tone_length, frequency, intensity, time_since_prev])\n","\n","                    del note_on_times_intensities[msg.dict()[\"note\"]]\n","\n","    features = np.array(features, dtype=np.float32)\n","\n","    if features.size > 0:\n","        features[:, 0] = features[:, 0] / (max_values[\"max_tone_length\"] if max_values is not None else 1)\n","        features[:, 1] = features[:, 1] / 127\n","        features[:, 2] = features[:, 2] / 127\n","        features[:, 3] = features[:, 3] / (max_values[\"max_time_since_prev\"] if max_values is not None else 1)\n","\n","    if max_values is not None:\n","        seq_len = max_values[\"max_seq_len\"]\n","        if len(features) < seq_len:\n","            padding = np.zeros((seq_len - len(features), 4))\n","            features = np.vstack([features, padding])\n","        else:\n","            features = features[:seq_len]\n","\n","    return features"],"metadata":{"id":"U_aHP3Ml2XbQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is the function to get a dict of the max values for each metric in order to normalize them for training:"],"metadata":{"id":"R_85orGnTGpB"}},{"cell_type":"code","source":["def get_max_values(metadata):\n","    all_tone_lengths = []\n","    all_time_since_prev = []\n","\n","    filenames = [os.path.join(\"/content/drive/MyDrive/Piano generation/Project/MAESTRO dataset/maestro-v3.0.0-midi/maestro-v3.0.0/\", filename) for filename in metadata[metadata[\"split\"] == \"train\"][\"midi_filename\"]]\n","\n","    for file in tqdm(filenames):\n","        features = preprocess_midi(file)\n","\n","        all_tone_lengths.append(features[:, 0])\n","        all_time_since_prev.append(features[:, 3])\n","\n","    all_tone_lengths = np.concatenate(all_tone_lengths)\n","    all_time_since_prev = np.concatenate(all_time_since_prev)\n","\n","    max_values = {}\n","\n","    max_values[\"max_tone_length\"] = np.max(all_tone_lengths)\n","    max_values[\"max_time_since_prev\"] = np.max(all_time_since_prev)\n","\n","    return max_values"],"metadata":{"id":"lG64AG2XqIbt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is the dataset we are going to use. Upon initializing, it converts all of the midi files into the desired representation. Then, when `__getitem__` is called, it just returns a song."],"metadata":{"id":"GPKjMlvpTNNW"}},{"cell_type":"code","source":["class GanMusicDataset(Dataset):\n","    def __init__(self, metadata):\n","        super().__init__()\n","        filenames = [os.path.join(\"/content/drive/MyDrive/Piano generation/Project/MAESTRO dataset/maestro-v3.0.0-midi/maestro-v3.0.0/\", filename) for filename in metadata[\"midi_filename\"]]\n","        self.songs = []\n","        max_values = get_max_values(metadata)\n","\n","        for file in tqdm(filenames):\n","            features = preprocess_midi(file, max_values=max_values)\n","            self.songs.append(torch.from_numpy(features))\n","\n","        self.songs = torch.stack(self.songs)\n","\n","    def __len__(self):\n","        return len(self.songs)\n","\n","    def __getitem__(self, idx):\n","        return self.songs[idx]"],"metadata":{"id":"56M5Rv9WAt0Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Again, it's way faster if we load it from a file."],"metadata":{"id":"Ph8tYJuFTfWT"}},{"cell_type":"code","source":["music_dataset_train = torch.load(\"/content/drive/MyDrive/Piano generation/Project/saved_data/datasets/train/gan_music_dataset_train.pt\", weights_only=False)"],"metadata":{"id":"KTZl8j8CAxkG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here is out generator. It's a simple architecture with juts 2 LSTM layers and a Linear layer to project the output to the desired dimensions."],"metadata":{"id":"NLQ3AEGWTjsc"}},{"cell_type":"code","source":["class Generator(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(Generator, self).__init__()\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_sizet, num_layers=2, batch_first=True)\n","        self.ff = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, z):\n","        out, _ = self.lstm(z)\n","        out = self.ff(out)\n","\n","        return out"],"metadata":{"id":"p_f0vspkF7-W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This is the discriminator. It's again a simple architecture with 2 LSTM layers, although this time they are bidirectional. Again, in the end there is a Linear layer, which combines all of the outputs in a single dimension to tell if it's real or not."],"metadata":{"id":"JkgWjUAFTyll"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Discriminator, self).__init__()\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, bidirectional=True, batch_first=True)\n","        self.ff = nn.Linear(hidden_size * 4, 1)\n","\n","    def forward(self, x):\n","        out, (h_n, c_n) = self.lstm(x)\n","\n","        final_h = torch.cat((h_n[-2,:], h_n[-1,:]), dim=1)\n","        final_c = torch.cat((c_n[-2,:], c_n[-1,:]), dim=1)\n","\n","        combined_state = torch.cat((final_h, final_c), dim=1)\n","\n","        x = self.ff(combined_state)\n","\n","        return x"],"metadata":{"id":"C-Q_08WXO2rT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["music_dataloader_train = DataLoader(music_dataset_train, batch_size=2, shuffle=True)"],"metadata":{"id":"Jm4P7fk7hHvj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we initialize the hyperparameters for both models with their hidden size being 350, as inspired again by the same papaer ([Olof Morgen](https://arxiv.org/abs/1611.09904)). The output size of the generator and the input size of the discriminator are both 4, because that's what the data representation requires. This time we are going to experiment with different values for the betas argument, beginning with 0.5 for beta1 and 0.999 for beta2."],"metadata":{"id":"akDBr49-UJiG"}},{"cell_type":"code","source":["generator = Generator(input_size=100, hidden_size=350, output_size=4).to(device)\n","discriminator = Discriminator(input_size=4, hidden_size=350).to(device)\n","\n","optimizer_G = optim.AdamW(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_D = optim.AdamW(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","criterion = nn.BCELoss()"],"metadata":{"id":"hpJdSlxlf0DM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_gan(generator, discriminator, optimizer_d, optimizer_g, criterion, num_epochs, generator_loss_history, discriminator_loss_history, epochs_count=1, create_plot=True):\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","\n","        for i, real_data in tqdm(enumerate(music_dataloader_train), f\"Epoch {epoch+epochs_count}:\"):\n","            real_data = real_data.to(device).float()\n","\n","            z = torch.randn(real_data.size(0), real_data.size(1), 100, dtype=torch.float32).to(device)\n","            fake_data = generator(z)\n","\n","            optimizer_d.zero_grad()\n","\n","            real_labels = torch.ones(real_data.size(0), 1).to(device).float()\n","            fake_labels = torch.zeros(fake_data.size(0), 1).to(device).float()\n","\n","            real_output = discriminator(real_data)\n","            fake_output = discriminator(fake_data)\n","\n","            real_loss = criterion(real_output, real_labels)\n","            fake_loss = criterion(fake_output, fake_labels)\n","\n","            d_loss = real_loss + fake_loss\n","            d_loss.backward(retain_graph=True)\n","            optimizer_d.step()\n","\n","            discriminator_loss_history.append(d_loss.item())\n","\n","            optimizer_g.zero_grad()\n","\n","            fake_labels = torch.zeros(fake_data.size(0), 1).to(device)\n","            fake_output = discriminator(fake_data)\n","\n","            g_loss = criterion(fake_output, fake_labels)\n","            g_loss.backward()\n","            optimizer_g.step()\n","\n","            generator_loss_history.append(g_loss.item())\n","\n","        torch.save(generator.state_dict(), f\"/content/drive/MyDrive/Piano generation/Project/saved_data/saved_models/gan_generator_epoch_{epoch+epochs_count}.pt\")\n","        torch.save(discriminator.state_dict(), f\"/content/drive/MyDrive/Piano generation/Project/saved_data/saved_models/gan_discriminator_epoch_{epoch+epochs_count}.pt\")\n","\n","    if create_plot:\n","        plt.plot(generator_loss_history, label=\"Generator loss\")\n","        plt.plot(discriminator_loss_history, label=\"Discriminator loss\")\n","        plt.xlabel(\"Epoch\")\n","        plt.ylabel(\"Loss\")\n","        plt.title(\"Training Loss\")\n","        plt.legend()\n","        plt.show()\n","        plt.savefig(f\"/content/drive/MyDrive/Piano generation/Project/saved_data/plots/gan_loss_epoch_{epoch+num_epochs}_plot.png\")\n","\n","    return generator_loss_history, discriminator_loss_history"],"metadata":{"id":"ZGQXiF51dfKG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's try to run 10 epochs:"],"metadata":{"id":"uyvTLvqJWL12"}},{"cell_type":"code","source":["generator_loss_history, discriminator_loss_history = train_gan(generator, discriminator, optimizer_G, optimizer_D, criterion, 10, [], [])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"xD7wt3cYmYrA","executionInfo":{"status":"error","timestamp":1739534594079,"user_tz":0,"elapsed":10367,"user":{"displayName":"Georgi Goranov","userId":"05647327236610301206"}},"outputId":"5eae402c-dc5c-47c3-8143-e1170125cebe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1:: 0it [00:00, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:825: UserWarning: Error detected in MmBackward0. Traceback of forward call that caused the error:\n","  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 699, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, f))\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 750, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 824, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 785, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 249, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 747, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 785, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-15-eeb51904f0e3>\", line 1, in <cell line: 0>\n","    generator_loss_history, discriminator_loss_history = train_gan(generator, discriminator, optimizer_G, optimizer_D, criterion, 10, [], [])\n","  File \"<ipython-input-14-fcfb5f5b0a8e>\", line 9, in train_gan\n","    fake_data = generator(z)\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"<ipython-input-10-3aa8d44b3016>\", line 9, in forward\n","    out = self.ff(out)\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n","    return F.linear(input, self.weight, self.bias)\n"," (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:110.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","Epoch 1:: 0it [00:10, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [350, 4]], which is output 0 of AsStridedBackward0, is at version 3; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-eeb51904f0e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator_loss_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-fcfb5f5b0a8e>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, optimizer_d, optimizer_g, criterion, num_epochs, generator_loss_history, discriminator_loss_history, epochs_count, create_plot)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [350, 4]], which is output 0 of AsStridedBackward0, is at version 3; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"]}]},{"cell_type":"markdown","source":["Due to time constraints, I couldn't fix this problem."],"metadata":{"id":"-MHc_tDVWN-k"}},{"cell_type":"code","source":[],"metadata":{"id":"-WX6d516ml7-"},"execution_count":null,"outputs":[]}]}